import { CohereClient } from 'cohere-ai'
import {
  ApiMetaBilledUnits,
  ChatRequest,
  FinishReason,
  Message,
  StreamedChatResponse,
  Tool,
  ToolResult,
} from 'cohere-ai/api'
import { Stream } from 'cohere-ai/core'
import { nanoid } from 'nanoid'
import {
  ChatCompletionAssistantMessageParam,
  ChatCompletionMessageToolCall,
  ChatCompletionToolMessageParam,
} from 'openai/resources/index'
import { ChatCompletionTool } from 'openai/src/resources/index.js'

import {
  CohereModel,
  CompletionParams,
  ProviderCompletionParams,
} from '../chat'
import { CompletionResponse, StreamCompletionResponse } from '../userTypes'
import { BaseHandler } from './base'
import { InputError, InvariantError, MessageRole } from './types'
import { consoleWarn, getTimestamp } from './utils'

type CohereMessageRole = 'CHATBOT' | 'SYSTEM' | 'USER' | 'TOOL'

const convertRole = (role: MessageRole): CohereMessageRole => {
  if (role === 'assistant') {
    return 'CHATBOT'
  } else if (role === 'system') {
    return 'SYSTEM'
  } else if (role === 'tool') {
    return 'TOOL'
  } else if (role === 'user') {
    return 'USER'
  } else {
    throw new InputError(`Unknown role: ${role}`)
  }
}

const convertFinishReason = (
  finishReason?: FinishReason
): CompletionResponse['choices'][0]['finish_reason'] => {
  if (
    finishReason === 'COMPLETE' ||
    finishReason === 'USER_CANCEL' ||
    finishReason === 'STOP_SEQUENCE'
  ) {
    return 'stop'
  } else if (finishReason === 'MAX_TOKENS') {
    return 'length'
  } else if (finishReason === 'ERROR_TOXIC') {
    return 'content_filter'
  } else if (finishReason === 'ERROR_LIMIT') {
    // OpenAI throws an error in when the model's context limit is reached, so we do too for consistency.
    throw new Error(
      `The generation could not be completed because the modelâ€™s context limit was reached.`
    )
  } else if (finishReason === 'ERROR') {
    throw new Error(`The generation could not be completed due to an error.`)
  } else {
    return 'unknown'
  }
}

const popLastUserMessageContentString = (
  messages: CompletionParams['messages']
): string => {
  for (let i = messages.length - 1; i >= 0; i--) {
    const message = messages[i]
    if (message.role === 'user') {
      if (typeof message.content === 'string') {
        messages.splice(i, 1) // Remove the object from the array
        return message.content
      } else if (Array.isArray(message.content)) {
        for (const e of message.content) {
          if (e.type === 'text') {
            messages.splice(i, 1) // Remove the object from the array
            return e.text
          }
        }
      }
    }
  }

  // Return a placeholder string if the user didn't include a text message. We include a whitespace
  // in the string because Cohere throws an error if the user's message contains zero tokens.
  return 'Empty'
}

const convertStopSequences = (
  stop?: CompletionParams['stop']
): Array<string> | undefined => {
  if (stop === null || stop === undefined) {
    return undefined
  } else if (typeof stop === 'string') {
    return [stop]
  } else if (Array.isArray(stop) && stop.every((e) => typeof e === 'string')) {
    return stop
  } else {
    throw new Error(`Unknown stop sequence type: ${stop}`)
  }
}

export const toCohereTool = (tool: ChatCompletionTool): Tool => {
  const convertType = (
    type: string,
    properties?: any,
    additionalProperties?: any
  ): string => {
    switch (type) {
      case 'string':
        return 'str'
      case 'integer':
        return 'int'
      case 'array':
        return `List${properties ? `[${convertType(properties.type)}]` : ''}`
      case 'object':
        if (additionalProperties) {
          return `Dict[str, ${convertType(additionalProperties.type)}]`
        }
        return 'Dict'
      default:
        return type
    }
  }

  const convertProperties = (
    properties: Record<string, any>,
    requiredFields: string[]
  ): Record<string, any> => {
    const converted: Record<string, any> = {}
    for (const [key, value] of Object.entries(properties)) {
      const isRequired = requiredFields.includes(key)
      converted[key] = {
        description: value.description,
        type: convertType(value.type, value.items, value.additionalProperties),
        required: isRequired,
      }
      if (value.type === 'object' && value.properties) {
        converted[key].properties = convertProperties(
          value.properties,
          value.required || []
        )
      }
    }
    return converted
  }

  const required: string[] = Array.isArray(tool.function.parameters?.required)
    ? tool.function.parameters?.required
    : []
  const parameterDefinitions = tool.function.parameters?.properties
    ? convertProperties(tool.function.parameters.properties, required)
    : undefined

  return {
    name: tool.function.name,
    description: tool.function.description ?? '',
    parameterDefinitions,
  }
}

const getUsageTokens = (
  billedUnits?: ApiMetaBilledUnits
): CompletionResponse['usage'] => {
  if (
    billedUnits &&
    typeof billedUnits.inputTokens === 'number' &&
    typeof billedUnits.outputTokens === 'number'
  ) {
    const { inputTokens, outputTokens } = billedUnits
    return {
      completion_tokens: outputTokens,
      prompt_tokens: inputTokens,
      total_tokens: outputTokens + inputTokens,
    }
  } else {
    return undefined
  }
}

const popLastToolMessageParams = (
  messages: CompletionParams['messages']
): Array<ChatCompletionToolMessageParam> | undefined => {
  const lastMessage = messages.at(messages.length - 1)
  if (lastMessage === undefined || lastMessage.role !== 'tool') {
    return undefined
  }

  const toolMessages: Array<ChatCompletionToolMessageParam> = []
  for (let i = messages.length - 1; i >= 0; i--) {
    const message = messages[i]
    if (message.role === 'tool') {
      // Put the new element at the beginning of the array to maintain the same order as the
      // messages array. (This is necessary because we're iterating from the end of the messages
      // array to the beginning).
      toolMessages.unshift(message)

      messages.pop()
    }
  }

  return toolMessages
}

/**
 * @param previousMessages All of the messages before the `toolMessage`.
 */
const toToolResult = (
  toolMessage: ChatCompletionToolMessageParam,
  previousMessages: CompletionParams['messages']
): ToolResult => {
  // Find the most recent assistant message, which contains the function arguments. The assistant
  // message must immediately precede the tool messages in order to adhere to OpenAI's API.
  let lastAssistantMessage: ChatCompletionAssistantMessageParam | null = null
  for (let i = previousMessages.length - 1; i >= 0; i--) {
    const message = previousMessages[i]
    if (message.role === 'tool') {
      continue
    } else if (message.role === 'assistant') {
      lastAssistantMessage = message
      break
    } else {
      throw new Error(
        `Expected an assistant message to precede tool messages, but detected a message from the ${message.role} role instead.`
      )
    }
  }

  // The following errors can occur due to a bug in our code or due to the user incorrectly handling
  // assistant and/or tool messages.
  if (lastAssistantMessage === null) {
    // OpenAI enforces that an assistant message must precede tool messages, and since we need the
    // assistant message to get the function arguments, we throw an error if we can't find it.
    throw new Error(
      `Could not find message from the 'assistant' role, which must precede messages from the 'tool' role.`
    )
  }
  if (lastAssistantMessage.tool_calls === undefined) {
    throw new Error(
      `Expected 'assistant' message to contain a 'tool_calls' field because it precedes tool call messages, but no 'tool_calls' field was found.`
    )
  }
  const toolCall = lastAssistantMessage.tool_calls.find(
    (t) => t.id === toolMessage.tool_call_id
  )
  if (!toolCall) {
    throw new Error(
      `Could not find the following tool call ID in the 'assistant' message: ${toolMessage.tool_call_id}`
    )
  }

  const toolResult: ToolResult = {
    call: {
      name: toolCall.function.name,
      parameters: JSON.parse(toolCall.function.arguments),
    },
    outputs: [JSON.parse(toolMessage.content)],
  }
  return toolResult
}

export const convertMessages = (
  unclonedMessages: CompletionParams['messages']
): {
  messages: Array<Message>
  lastUserMessage: string
  toolResults: ChatRequest['toolResults']
} => {
  const clonedMessages = structuredClone(unclonedMessages)

  // Cohere has a distinct field, `toolResults`, for the most recent tool messages. If the user's
  // `message` ends with tool messages, we pop them from the array in order to populate this field.
  const lastToolMessages = popLastToolMessageParams(clonedMessages)
  const lastToolResults = lastToolMessages?.map((toolMessage) =>
    toToolResult(toolMessage, clonedMessages)
  )

  // Cohere throws the following error if the `toolResults` field is defined and the `message` field
  // is a non-empty string: 'invalid request: cannot specify both message and tool_results in
  // multistep mode'. To avoid this error, we only populate the user message if the `toolResults`
  // aren't defined.
  const lastUserMessage =
    lastToolResults === undefined
      ? popLastUserMessageContentString(clonedMessages)
      : ''

  const chatHistory: ChatRequest['chatHistory'] = []
  for (let i = 0; i < clonedMessages.length; i++) {
    const message = clonedMessages[i]
    if (message.role === 'tool') {
      const newToolResult = toToolResult(message, clonedMessages.slice(0, i))
      const lastChatHistoryMessage = chatHistory.at(chatHistory.length - 1)
      if (
        lastChatHistoryMessage !== undefined &&
        lastChatHistoryMessage.role === 'TOOL'
      ) {
        if (lastChatHistoryMessage.toolResults === undefined) {
          // We manually populate the `toolResults` array when creating the `TOOL` message, so it
          // should always be defined here.
          throw new InvariantError(`The 'toolResults' field is undefined.`)
        }

        lastChatHistoryMessage.toolResults.push(newToolResult)
      } else {
        chatHistory.push({
          role: 'TOOL',
          toolResults: [newToolResult],
        })
      }
    } else if (message.role === 'assistant') {
      chatHistory.push({
        role: convertRole(message.role),
        message: message.content ?? '',
        toolCalls: message.tool_calls?.map((toolCall) => {
          return {
            name: toolCall.function.name,
            parameters: JSON.parse(toolCall.function.arguments),
          }
        }),
      })
    } else if (typeof message.content === 'string') {
      chatHistory.push({
        role: convertRole(message.role),
        message: message.content,
      })
    } else if (Array.isArray(message.content)) {
      for (const e of message.content) {
        if (e.type === 'text') {
          chatHistory.push({
            role: convertRole(message.role),
            message: e.text,
          })
        }
      }
    }
  }

  return {
    messages: chatHistory,
    lastUserMessage,
    toolResults: lastToolResults,
  }
}

export const convertTools = (
  tools: CompletionParams['tools'],
  toolChoice: CompletionParams['tool_choice']
): ChatRequest['tools'] => {
  if (toolChoice === 'none' || tools === undefined) {
    return undefined
  } else {
    return tools.map(toCohereTool)
  }
}

async function* createCompletionResponseStreaming(
  response: Stream<StreamedChatResponse>,
  model: CohereModel,
  created: number
): StreamCompletionResponse {
  let id: string | undefined
  // Mapping from tool call index to tool call ID. We need to maintain a mapping because we create
  // our own tool call IDs and because we only want to assign a tool call index to a single ID, even
  // when its content is streamed across many chunks.
  const toolCallIdMap: Map<number, string> = new Map()

  for await (const chunk of response) {
    if (chunk.eventType === 'stream-start') {
      id = chunk.generationId
      yield {
        choices: [
          {
            index: 0,
            finish_reason: null,
            logprobs: null,
            delta: {
              role: 'assistant',
            },
          },
        ],
        created,
        model,
        id: chunk.generationId,
        object: 'chat.completion.chunk',
      }
    }

    if (id === undefined) {
      // Should never happen because the 'stream-start' event, where the `id` field is assigned,
      // occurs first.
      throw new InvariantError(`The generated ID is undefined.`)
    }

    if (chunk.eventType === 'stream-end') {
      yield {
        choices: [
          {
            index: 0,
            finish_reason: convertFinishReason(chunk.finishReason),
            logprobs: null,
            // We return an empty delta because the returned text in the 'stream-end' event contains
            // the aggregated response.
            delta: {},
          },
        ],
        created,
        model,
        id,
        object: 'chat.completion.chunk',
      }
    } else if (
      chunk.eventType === 'text-generation' ||
      // Cohere's documentation states that a `text` field can exist on 'tool-calls-chunk' chunks if
      // the chunk does not contain a `toolCallIndex` field. However, Cohere's TypeScript type does
      // not contain a text field, which appears to be a bug. We must manually cast to the chunk to
      // `any` in order to determine whether it has a `text` field in this scenario. If the field
      // exists, we treat the chnk like a 'text-generation' chunk.
      (chunk.eventType === 'tool-calls-chunk' &&
        typeof (chunk as any).text === 'string')
    ) {
      const text = (chunk as any).text
      yield {
        choices: [
          {
            index: 0,
            finish_reason: null,
            logprobs: null,
            delta: {
              content: text,
            },
          },
        ],
        created,
        model,
        id,
        object: 'chat.completion.chunk',
      }
    } else if (chunk.eventType === 'tool-calls-chunk') {
      const index = chunk.toolCallDelta.index
      if (typeof index !== 'number') {
        throw new InvariantError(`Content block index is undefined.`)
      }

      let toolCallId = toolCallIdMap.get(index)
      if (toolCallId === undefined) {
        toolCallId = nanoid()
        toolCallIdMap.set(index, toolCallId)
      }

      yield {
        choices: [
          {
            index: 0,
            finish_reason: null,
            logprobs: null,
            delta: {
              content: chunk.toolCallDelta.text,
              tool_calls: [
                {
                  index,
                  id: toolCallId,
                  type: 'function',
                  function: {
                    name: chunk.toolCallDelta.name,
                    arguments: chunk.toolCallDelta.parameters,
                  },
                },
              ],
            },
          },
        ],
        created,
        model,
        id,
        object: 'chat.completion.chunk',
      }
    }
  }
}

export class CohereHandler extends BaseHandler<CohereModel> {
  async create(
    body: ProviderCompletionParams<'cohere'>
  ): Promise<CompletionResponse | StreamCompletionResponse> {
    this.validateInputs(body)

    if (this.opts.baseURL) {
      consoleWarn(
        `The 'baseUrl' will be ignored by Cohere because it does not support this field.`
      )
    }

    if (typeof body.n === 'number' && body.n > 1) {
      throw new InputError(
        `Cohere does not support setting 'n' greater than 1.`
      )
    }

    const apiKey = this.opts.apiKey ?? process.env.COHERE_API_KEY
    if (apiKey === undefined) {
      throw new InputError(
        "No Cohere API key detected. Please define an 'COHERE_API_KEY' environment variable or supply the API key using the 'apiKey' parameter."
      )
    }

    const maxTokens = body.max_tokens ?? undefined
    const p = body.top_p ?? undefined
    const stopSequences = convertStopSequences(body.stop)
    const temperature =
      typeof body.temperature === 'number'
        ? // We divide by two because Cohere's temperature range is 0 to 1 and the input temperature
          // range is 0 to 2.
          body.temperature / 2
        : undefined
    const tools = convertTools(body.tools, body.tool_choice)

    const { messages, lastUserMessage, toolResults } = convertMessages(
      body.messages
    )

    const input = {
      maxTokens,
      message: lastUserMessage,
      chatHistory: messages,
      model: body.model,
      stopSequences,
      temperature,
      p,
      toolResults,
      tools,
    }
    const cohere = new CohereClient({
      token: apiKey,
    })

    if (body.stream === true) {
      const created = getTimestamp()
      const response = await cohere.chatStream(input)
      return createCompletionResponseStreaming(response, body.model, created)
    } else {
      const created = getTimestamp()
      const response = await cohere.chat(input)

      const toolCalls: Array<ChatCompletionMessageToolCall> | undefined =
        response.toolCalls?.map((toolCall) => {
          return {
            type: 'function',
            id: nanoid(),
            function: {
              name: toolCall.name,
              arguments: JSON.stringify(toolCall.parameters),
            },
          }
        })

      const usage = getUsageTokens(response.meta?.billedUnits)
      const convertedResponse: CompletionResponse = {
        object: 'chat.completion',
        choices: [
          {
            finish_reason: convertFinishReason(response.finishReason),
            index: 0,
            logprobs: null,
            message: {
              role: 'assistant',
              content: response.text,
              tool_calls: toolCalls,
            },
          },
        ],
        created,
        id: response.generationId ?? null,
        model: body.model,
        usage,
      }

      return convertedResponse
    }
  }
}
